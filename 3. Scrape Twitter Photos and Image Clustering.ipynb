{
 "cells": [
  {
   "cell_type": "raw",
   "id": "90163c9b",
   "metadata": {},
   "source": [
    "!pip install bot-studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae45f263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c7268fa6",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "final1=[]\n",
    "URL = ''\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(URL)\n",
    "time.sleep(2)\n",
    "\n",
    "while True:\n",
    "#     page = urllib.request.urlopen(URL)\n",
    "#     soup = BeautifulSoup(page)\n",
    "    content = driver.page_source\n",
    "    soup = BeautifulSoup(content)\n",
    "    for item in soup.findAll('img'):\n",
    "        if not item['src'] in final1:\n",
    "            final1.append(item['src'])\n",
    "    try:\n",
    "        WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.ID,\"loader-more-btn\"))).click()\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        break\n",
    "print(\"Total number of elements:  {}\".format(len(final1)))\n",
    "print(final1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dd5554",
   "metadata": {},
   "outputs": [],
   "source": [
    "final1_df = pd.DataFrame(final1)\n",
    "final1_df.to_excel('images.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe25f716",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = pd.read_excel('images.xlsx')\n",
    "images.columns = ['No.', 'Link']\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ef81be",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_list = images[\"Link\"].to_list()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "938036ff",
   "metadata": {},
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "for num, link in enumerate(link_list):\n",
    "    image = requests.get(link)\n",
    "    if 200 == image.status_code:\n",
    "        with open(\"pictures/image{}.jpg\".format(num+1), 'wb') as f:\n",
    "            f.write(image.content)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e9d9fd9a",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "path=[]\n",
    "for root, dirs,files in os.walk('pictures'):  \n",
    "    for fname in files:\n",
    "        path.append(os.path.join(root, fname))\n",
    "for x in path:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45213e50",
   "metadata": {},
   "source": [
    "Another way to scrape images is using bot_studio but it is not working very well?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2bdac7ab",
   "metadata": {},
   "source": [
    "from bot_studio import *"
   ]
  },
  {
   "cell_type": "raw",
   "id": "394939bc",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "twitter=bot_studio.twitter()\n",
    "twitter.open('https://twitter.com/xxx/media')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "995523fe",
   "metadata": {},
   "source": [
    "data=[]\n",
    "lastpage=''\n",
    "currentpage=''\n",
    "while(True):\n",
    "    currentpage=twitter.get_page_source()\n",
    "    if(lastpage==currentpage):\n",
    "        break\n",
    "    response=twitter.save_image_links()\n",
    "    for key in response['body']:\n",
    "        #key={'Imagelink': 'Imagelink'}\n",
    "        data.extend(list(key.values()))\n",
    "    twitter.scroll()\n",
    "    lastpage=currentpage"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9dedefd1",
   "metadata": {},
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "760c3f26",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "df = pd.DataFrame(data)\n",
    "#df.to_excel('images.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebde7cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "from clustimage import Clustimage\n",
    "\n",
    "# Initialize with default settings.\n",
    "cl = Clustimage(method='pca', grayscale=False)\n",
    "\n",
    "path = 'xx'\n",
    "# load images\n",
    "pathnames = path\n",
    "\n",
    "# Run the model to find the optimal clusters.\n",
    "results = cl.fit_transform(pathnames)\n",
    "\n",
    "# Make scatter plots\n",
    "cl.scatter()\n",
    "\n",
    "# More input arguments for the scatterplot\n",
    "cl.scatter(dotsize=35)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8799aeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['img']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9067fb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "from clustimage import Clustimage\n",
    "\n",
    "# init\n",
    "cl = Clustimage(method='pca', grayscale=False)\n",
    "# cl = Clustimage(method='pca-hog')\n",
    "\n",
    "# load images\n",
    "pathnames = path\n",
    "\n",
    "# Cluster images using the input pathnames.\n",
    "results = cl.fit_transform(pathnames, min_clust=3, max_clust=13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0149fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81c94f7",
   "metadata": {},
   "source": [
    "#### Detect unique images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3067c8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique images\n",
    "unique_samples = cl.unique()\n",
    "#\n",
    "print(unique_samples.keys())\n",
    "# ['labels', 'idx', 'xycoord_center', 'pathnames']\n",
    "#\n",
    "# Collect the unique images from the input\n",
    "pathnames[unique_samples['idx'],:]\n",
    "\n",
    "# Plot unique images.\n",
    "#cl.plot_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a293707",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_samples['idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6a4ed1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot all images per cluster\n",
    "cl.plot(cmap='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bf31dd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make various plots:\n",
    "\n",
    "# Silhouette plots\n",
    "cl.clusteval.plot()\n",
    "cl.clusteval.scatter(cl.results['xycoord'])\n",
    "\n",
    "# PCA explained variance plot\n",
    "# cl.pca.plot()\n",
    "\n",
    "# Dendrogram\n",
    "cl.dendrogram()\n",
    "\n",
    "# Plot unique image per cluster\n",
    "cl.plot_unique(img_mean=False)\n",
    "\n",
    "# Scatterplot\n",
    "cl.scatter(dotsize=50, zoom=0.5, img_mean=False)\n",
    "\n",
    "# Plot images per cluster or all clusters\n",
    "cl.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08839683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make scatterplot\n",
    "cl.scatter(zoom=None)\n",
    "\n",
    "# Plot the image that is in the center of the cluster\n",
    "cl.scatter(zoom=4)\n",
    "\n",
    "# Lets change some more arguments to make a pretty scatterplot\n",
    "cl.scatter(zoom=None, dotsize=200, figsize=(25, 15), args_scatter={'fontsize':24, 'gradient':'#FFFFFF', 'cmap':'Set2', 'legend':True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163ae46c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import library\n",
    "from clustimage import Clustimage\n",
    "\n",
    "# init\n",
    "cl = Clustimage(method='pca', grayscale=False, dim=(64,64))\n",
    "\n",
    "# Load example with faces\n",
    "X = cl.import_example(data='faces')\n",
    "\n",
    "# Preproceesing, cluster detection\n",
    "results = cl.fit_transform(X, min_clust=4, max_clust=20)\n",
    "\n",
    "# Make various plots:\n",
    "\n",
    "# Silhouette plots\n",
    "cl.clusteval.plot()\n",
    "cl.clusteval.scatter(cl.results['xycoord'])\n",
    "\n",
    "# Dendrogram\n",
    "cl.dendrogram()\n",
    "\n",
    "# Plot unique image per cluster\n",
    "cl.plot_unique(img_mean=False)\n",
    "\n",
    "# Scatterplot\n",
    "cl.scatter(dotsize=50, zoom=0.5, img_mean=False)\n",
    "\n",
    "# Plot images per cluster or all clusters\n",
    "cl.plot(labels=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7337da",
   "metadata": {},
   "source": [
    "### Cluster using Vision Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46b34eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "from PIL import Image as img\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cdd8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fb950c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array = img.open('pictures/image4.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff13095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = feature_extractor(images = image_array, \n",
    "                           return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad75b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_idx = logits.argmax(-1).item()\n",
    "\n",
    "print(\"Predicted class:\", model.config.id2label[predicted_class_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4296f9a9",
   "metadata": {},
   "source": [
    "### Cluster using VVG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1784e08b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade tensorflow --user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91595754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading/processing the images  \n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input \n",
    "\n",
    "# models \n",
    "from keras.applications.vgg16 import VGG16 \n",
    "from keras.models import Model\n",
    "\n",
    "# clustering and dimension reduction\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# for everything else\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2947a824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state path\n",
    "path = 'pictures/'\n",
    "\n",
    "# this list holds all the image filename\n",
    "images = []\n",
    "\n",
    "# creates a ScandirIterator aliased as files\n",
    "with os.scandir(path) as files:\n",
    "  # loops through each file in the directory\n",
    "    for file in files:\n",
    "        if file.name.endswith('.jpg'):\n",
    "          # adds only the image files to the flowers list\n",
    "            images.append('pictures/' + file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91edef82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16()\n",
    "model = Model(inputs = model.inputs, outputs = model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb791f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file, model):\n",
    "    # load the image as a 224x224 array\n",
    "    img = load_img(file, target_size=(224,224))\n",
    "    # convert from 'PIL.Image.Image' to numpy array\n",
    "    img = np.array(img) \n",
    "    # reshape the data for the model reshape(num_of_samples, dim 1, dim 2, channels)\n",
    "    reshaped_img = img.reshape(1,224,224,3) \n",
    "    # prepare image for model\n",
    "    imgx = preprocess_input(reshaped_img)\n",
    "    # get the feature vector\n",
    "    features = model.predict(imgx, use_multiprocessing=True)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a05758d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "p = r\"pictures/features\"\n",
    "\n",
    "# lop through each image in the dataset\n",
    "for img in images:\n",
    "    # try to extract the features and update the dictionary\n",
    "    try:\n",
    "        feat = extract_features(img,model)\n",
    "        data[img] = feat\n",
    "    # if something fails, save the extracted features as a pickle file (optional)\n",
    "    except:\n",
    "        with open(p,'wb') as file:\n",
    "            pickle.dump(data,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d6080e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of the filenames\n",
    "filenames = np.array(list(data.keys()))\n",
    "\n",
    "# get a list of just the features\n",
    "feat = np.array(list(data.values()))\n",
    "feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4d2669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of the filenames\n",
    "filenames = np.array(list(data.keys()))\n",
    "\n",
    "# get a list of just the features\n",
    "feat = np.array(list(data.values()))\n",
    "\n",
    "# reshape so that there are 210 samples of 4096 vectors\n",
    "feat = feat.reshape(-1,4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb32cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bab54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce the amount of dimensions in the feature vector\n",
    "pca = PCA(n_components=100, random_state=22)\n",
    "pca.fit(feat)\n",
    "x = pca.transform(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1014f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster feature vectors\n",
    "kmeans = KMeans(n_clusters=10, random_state=22)\n",
    "kmeans.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2fbc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# holds the cluster id and the images { id: [images] }\n",
    "groups = {}\n",
    "for file, cluster in zip(filenames,kmeans.labels_):\n",
    "    if cluster not in groups.keys():\n",
    "        groups[cluster] = []\n",
    "        groups[cluster].append(file)\n",
    "    else:\n",
    "        groups[cluster].append(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f916c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that lets you view a cluster (based on identifier)        \n",
    "def view_cluster(cluster):\n",
    "    plt.figure(figsize = (80,80));\n",
    "    # gets the list of filenames for a cluster\n",
    "    files = groups[cluster]\n",
    "    # only allow up to 30 images to be shown at a time\n",
    "    if len(files) > 100:\n",
    "        print(f\"Clipping cluster size from {len(files)} to 50\")\n",
    "        files = files[:99]\n",
    "    # plot each image in the cluster\n",
    "    \n",
    "    for index, file in enumerate(files):\n",
    "        #plt.title(\"Cluster \" + str(cluster))\n",
    "        plt.subplot(10,10,index+1);\n",
    "        img = load_img(file)\n",
    "        img = np.array(img)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cfab56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is just incase you want to see which value for k might be the best \n",
    "sse = []\n",
    "list_k = list(range(3, 50))\n",
    "\n",
    "for k in list_k:\n",
    "    km = KMeans(n_clusters=k, random_state=22)\n",
    "    km.fit(x)\n",
    "    \n",
    "    sse.append(km.inertia_)\n",
    "\n",
    "# Plot sse against k\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(list_k, sse)\n",
    "plt.xlabel(r'Number of clusters *k*')\n",
    "plt.ylabel('Sum of squared distance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2124f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_cluster(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d0e6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_cluster(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b55afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_cluster(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d837e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_cluster(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65bed38",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_cluster(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacb3b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_cluster(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54b1dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_cluster(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4fb2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_cluster(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d58d562",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_cluster(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844eb17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_cluster(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c1abcc",
   "metadata": {},
   "source": [
    "### Cluster using tSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd449fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff36e099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59027200",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images_to_plot = 1000\n",
    "\n",
    "if len(images) > num_images_to_plot:\n",
    "    sort_order = sorted(random.sample(range(len(images)), num_images_to_plot))\n",
    "    images = [images[i] for i in sort_order]\n",
    "    pca_features = [feat[i] for i in sort_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332fbc12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = np.array(feat)\n",
    "tsne = TSNE(n_components=2, learning_rate=150, perplexity=30, angle=0.2, verbose=2).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375e8310",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx, ty = tsne[:,0], tsne[:,1]\n",
    "tx = (tx-np.min(tx)) / (np.max(tx) - np.min(tx))\n",
    "ty = (ty-np.min(ty)) / (np.max(ty) - np.min(ty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f4b27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e9cc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 4000\n",
    "height = 3000\n",
    "max_dim = 100\n",
    "\n",
    "full_image = Image.new('RGBA', (width, height))\n",
    "for img, x, y in zip(images, tx, ty):\n",
    "    tile = Image.open(img)\n",
    "    rs = max(1, tile.width/max_dim, tile.height/max_dim)\n",
    "    tile = tile.resize((int(tile.width/rs), int(tile.height/rs)), Image.ANTIALIAS)\n",
    "    full_image.paste(tile, (int((width-max_dim)*x), int((height-max_dim)*y)), mask=tile.convert('RGBA'))\n",
    "\n",
    "plt.figure(figsize = (16,12))\n",
    "plt.imshow(full_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19391777",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(feat[:1000])\n",
    "tsne = TSNE(n_components=2, learning_rate=150, perplexity=30, angle=0.2, verbose=2).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba943ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterfairy\n",
    "\n",
    "# nx * ny = 1000, the number of images\n",
    "nx = 40\n",
    "ny = 25\n",
    "\n",
    "# assign to grid\n",
    "grid_assignment = rasterfairy.transformPointCloud2D(tsne, target=(nx, ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd678c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_width = 72\n",
    "tile_height = 56\n",
    "\n",
    "full_width = tile_width * nx\n",
    "full_height = tile_height * ny\n",
    "aspect_ratio = float(tile_width) / tile_height\n",
    "\n",
    "grid_image = Image.new('RGB', (full_width, full_height))\n",
    "\n",
    "for img, grid_pos in zip(images, grid_assignment[0]):\n",
    "    idx_x, idx_y = grid_pos\n",
    "    x, y = tile_width * idx_x, tile_height * idx_y\n",
    "    tile = Image.open(img)\n",
    "    tile_ar = float(tile.width) / tile.height  # center-crop the tile to match aspect_ratio\n",
    "    if (tile_ar > aspect_ratio):\n",
    "        margin = 0.5 * (tile.width - aspect_ratio * tile.height)\n",
    "        tile = tile.crop((margin, 0, margin + aspect_ratio * tile.height, tile.height))\n",
    "    else:\n",
    "        margin = 0.5 * (tile.height - float(tile.width) / aspect_ratio)\n",
    "        tile = tile.crop((0, margin, tile.width, margin + float(tile.width) / aspect_ratio))\n",
    "    tile = tile.resize((tile_width, tile_height), Image.ANTIALIAS)\n",
    "    grid_image.paste(tile, (int(x), int(y)))\n",
    "\n",
    "plt.figure(figsize = (16,12))\n",
    "plt.imshow(grid_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e332686",
   "metadata": {},
   "source": [
    "### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d63722",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.add_dll_directory(r\"C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Engine\\73BE2921551D\\ImplicitLibs\\cudart32_65.dll\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcfc908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def get_vector(input_image):\n",
    "    image = input_image.convert(\"RGB\")  # in case input image is not in RGB format\n",
    "    img_t = transform(image)\n",
    "    batch_t = torch.unsqueeze(img_t, 0)\n",
    "    my_embedding = torch.zeros([1, 512, 1, 1])\n",
    "    return my_embedding\n",
    "    \n",
    "def copy_data(m, i, o):\n",
    "    my_embedding.copy_(o.data)\n",
    "    h = layer.register_forward_hook(copy_data)\n",
    "    model(batch_t)\n",
    "    h.remove()\n",
    "    return my_embedding.squeeze().cpu().numpy()\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "layer = model._modules.get('avgpool')\n",
    "model.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647ead48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb3cdbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "im_path = 'pictures/'\n",
    "im_names = [os.path.join(root, name)\n",
    "            for root, dirs, files in os.walk(im_path)\n",
    "            for name in files\n",
    "            if name.endswith(\".jpg\")]\n",
    "existing_images_df = pd.DataFrame([re.findall(r\"[\\w']+\", im_name)[1:3] for im_name in im_names],\n",
    "                                  columns=['cat_id', 'pid'])\n",
    "existing_images_df['impath'] = im_names\n",
    "vecs = [list(get_vector(Image.open(impath))) for _, pid, impath in existing_images_df.values]\n",
    "with open('vis/feature_vecs.tsv', 'w') as fw:\n",
    "    csv_writer = csv.writer(fw, delimiter='\\t')\n",
    "    csv_writer.writerows(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6184becb",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [Image.open(filename).resize((300,300)) for filename in existing_images_df['impath']]\n",
    "image_width, image_height = images[0].size\n",
    "one_square_size = int(np.ceil(np.sqrt(len(images))))\n",
    "master_width = (image_width * one_square_size) \n",
    "master_height = image_height * one_square_size\n",
    "spriteimage = Image.new(\n",
    "    mode='RGBA',\n",
    "    size=(master_width, master_height),\n",
    "    color=(0,0,0,0))  # fully transparent\n",
    "for count, image in enumerate(images):\n",
    "    div, mod = divmod(count,one_square_size)\n",
    "    h_loc = image_width*div\n",
    "    w_loc = image_width*mod    \n",
    "    spriteimage.paste(image,(w_loc,h_loc))\n",
    "spriteimage.convert(\"RGB\").save('vis/sprite.jpg', transparency=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30992751",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = existing_images_df[['cat_id', 'pid']].to_csv('vis/metadata.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec00c1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "#import tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecfb83d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4d6fbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --ignore-installed tf-nightly --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f9d625",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cac53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer = tf.summary.create_file_writer('file path', sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35a6565",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir ./vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040ecd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir ./vis --host localhost --port 8098"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3038c7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard import notebook\n",
    "notebook.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4645138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control TensorBoard display. If no port is provided, \n",
    "# the most recently launched TensorBoard is used\n",
    "notebook.display(port=6006, height=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d07fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683bce0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "layer = model._modules.get('avgpool')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496d9d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = tf.keras.models.Model( \n",
    "    inputs=model.inputs, \n",
    "    outputs=model.layers[-1].output \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
